# Object-Detection-Using-OpenCV

ğŸ§  Project: Smart Glasses Object Detection + Voice Description

Goal:
Detect objects continuously through a camera, display them in a window with bounding boxes, and speak out whatâ€™s detected.


---

âš™ï¸ 1ï¸âƒ£ Prerequisites

- Before starting:

- Youâ€™re booted into Linux Mint Cinnamon.

- You have an internet connection.

- You have a USB webcam connected and working.


You can verify your webcam:

```
ls /dev/video*
```
If you see /dev/video0, itâ€™s connected correctly. âœ…


---

âš™ï¸ 2ï¸âƒ£ Update system

```
sudo apt update && sudo apt upgrade -y
```

---

âš™ï¸ 3ï¸âƒ£ Install required packages

```
sudo apt install python3-pip git python3-opencv espeak -y
```

---

âš™ï¸ 4ï¸âƒ£ Install Python libraries

```
pip3 install torch torchvision torchaudio ultralytics pyttsx3 --break-system-packages
```

ğŸ“¦ Explanation:

- torch, torchvision, torchaudio â†’ Machine learning backend for YOLO

- ultralytics â†’ YOLOv8 library (latest version)

- pyttsx3 â†’ Text-to-Speech

- opencv-python â†’ Already installed from step 3



---

âš™ï¸ 5ï¸âƒ£ Verify your camera

Run this simple command to ensure your camera is recognized:

```
python3 - <<'EOF'
import cv2
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ Camera not found!")
else:
    print("âœ… Camera working fine!")
cap.release()
EOF
```

If you get âœ… Camera working fine!, youâ€™re ready.


---

âš™ï¸ 6ï¸âƒ£ Download the YOLO model (automatically done on first run)

Weâ€™ll use the YOLOv8 nano model (yolov8n.pt) â€” itâ€™s lightweight but powerful.


---

âš™ï¸ 7ï¸âƒ£ Create the main Python file

Create a file named detect_and_speak.py:

```
nano detect_and_speak.py
```

Paste this complete code ğŸ‘‡


---

ğŸ Full Python Code: detect_and_speak.py
```
import cv2
import pyttsx3
from ultralytics import YOLO

# Initialize YOLOv8 model
model = YOLO("yolov8n.pt")  # downloads automatically first run

# Initialize text-to-speech engine
engine = pyttsx3.init()
engine.setProperty('rate', 150)

# Open webcam
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ Camera not detected!")
    exit()

print("âœ… Camera started. Press 'Q' to quit.")

last_spoken = ""  # to avoid repeating same object names

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ Failed to grab frame!")
        break

    # Run YOLO detection
    results = model(frame, verbose=False)

    # Get class names of detected objects
    detected = []
    for box in results[0].boxes:
        cls_id = int(box.cls[0])
        detected.append(results[0].names[cls_id])

    # Draw boxes and labels on frame
    annotated_frame = results[0].plot()

    # Speak detected objects if any
    if detected:
        # Remove duplicates
        detected = list(set(detected))
        sentence = "I can see " + ", ".join(detected)

        if sentence != last_spoken:
            print(sentence)
            engine.say(sentence)
            engine.runAndWait()
            last_spoken = sentence

    # Show the annotated frame
    cv2.imshow("Smart Glasses Camera View", annotated_frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```
Save and exit (press Ctrl + O, then Enter, then Ctrl + X).


---

âš™ï¸ 8ï¸âƒ£ Run your program

In terminal:

```
python3 detect_and_speak.py
```

âœ… You should now see:

- A window showing your camera feed

- Bounding boxes and labels over detected objects

- The system speaking aloud the object names (e.g. â€œI can see person, chairâ€)


Press Q to exit.


---

âš™ï¸ 9ï¸âƒ£ (Optional) Auto-start on boot (for future)

Later, when you move this to a Raspberry Pi, you can set it to run automatically using:

```
sudo nano /etc/rc.local
```

and add this line before exit 0:

```
python3 /home/pi/detect_and_speak.py &
```

---

âš™ï¸ ğŸ”Ÿ Troubleshooting

Problem	Fix

No module named torch	Re-run pip3 install torch torchvision torchaudio --break-system-packages
cv2.imshow crashes	Reduce window resolution or run sudo apt install python3-opencv again
No audio	Check espeak works: run espeak "hello world"
Laggy video	Use smaller model (yolov8n.pt) and close other apps



---

ğŸ§  1ï¸âƒ£1ï¸âƒ£ Notes & Drawbacks

Limitation	Explanation

ğŸ§® CPU-only inference	YOLO runs slower (~3â€“5 FPS) without GPU
ğŸ”Š Repetitive speech	Code limits repeats with last_spoken variable
ğŸ§  Limited accuracy	YOLOv8n detects 80 COCO objects (person, car, chair, etc.)
ğŸ”‹ High CPU use	Constant video + TTS can use ~60â€“80% CPU on PC
âš¡ Slow USB	Live USB storage can cause small lag



---

âœ… In Summary

|Step|	Command|
----------------
||Update system|	sudo apt update && sudo apt upgrade -y
|Install base tools|	sudo apt install python3-pip git python3-opencv |espeak -y
|Install libraries|	pip3 install torch torchvision torchaudio |ultralytics pyttsx3 --break-system-packages
|Run code|	python3 detect_and_speak.py



---

ğŸ§© Example Output

A camera window titled â€œSmart Glasses Camera Viewâ€

Green boxes with labels like:

```
person
bottle
chair
```

Voice output saying:
â€œI can see person and bottle.â€

---

